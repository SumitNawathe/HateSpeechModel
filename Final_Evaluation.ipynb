{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Evaluation",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db593edfcb174c8aa6b920a45e098b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32d16ab5561f458588ee241e8d5cfbe4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b46d5f2969364a27a2e47e56e6e43ddf",
              "IPY_MODEL_addba4278f404e60bbe6fbd193387264",
              "IPY_MODEL_ee5b76fe36f34b2498dc0feed1cd1e79"
            ]
          }
        },
        "32d16ab5561f458588ee241e8d5cfbe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b46d5f2969364a27a2e47e56e6e43ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_738bc9c8486846b48c9be5dda08b00ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c3a81ffdaa7432395e4b5307fc8155a"
          }
        },
        "addba4278f404e60bbe6fbd193387264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f082a846a28449087194e1e06ad77a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdb36c9cef1d4c8c8e4bcecde2b606d9"
          }
        },
        "ee5b76fe36f34b2498dc0feed1cd1e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97339142b419463ba69cce57eca2771a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2306/2306 [00:50&lt;00:00, 46.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4448356d2a094d19bcecdfa6a9c5f4c1"
          }
        },
        "738bc9c8486846b48c9be5dda08b00ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c3a81ffdaa7432395e4b5307fc8155a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f082a846a28449087194e1e06ad77a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdb36c9cef1d4c8c8e4bcecde2b606d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97339142b419463ba69cce57eca2771a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4448356d2a094d19bcecdfa6a9c5f4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumitNawathe/HateSpeechModel/blob/main/Final_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs/Upgrades"
      ],
      "metadata": {
        "id": "fAZREGLm9KoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QDN9glRYXLiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFdcLwdKqrhg"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install pytorch-lightning\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "7IT4IZaJ9Ng3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas\n",
        "!pip3 install pickle5"
      ],
      "metadata": {
        "id": "eyYD_Nt-9PCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "tCyisNoE9QpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle5 as pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "#from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.functional import accuracy, f1, auroc\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "pl.seed_everything(RANDOM_SEED)\n",
        "\n",
        "import gc\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AdamW"
      ],
      "metadata": {
        "id": "En4TccRt9R81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data/Model"
      ],
      "metadata": {
        "id": "BlQ_pcif_EbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('hatespeech_df_encodedv2.pickle', 'rb') as hatespeech_df_file:\n",
        "  hatespeech_df = pickle.load(hatespeech_df_file)\n",
        "hatespeech_df.shape, hatespeech_df.keys()"
      ],
      "metadata": {
        "id": "y0v1Ilez_GHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf1d98c-ed06-467d-b6a4-a3550afd40de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23055, 16),\n",
              " Index(['text', 'jew', 'language', 'race', 'black', 'immigrant', 'other_race',\n",
              "        'religion', 'muslim', 'gender', 'women', 'lgbt', 'disability',\n",
              "        'not_hate', 'asian', 'encoding'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# temp fix, remove after running\n",
        "hatespeech_df.loc[hatespeech_df[hatespeech_df['immigrant'] == 1].index, 'race'] = 1"
      ],
      "metadata": {
        "id": "uHbaNtZX_K5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKEN_COUNT = 768\n",
        "MODEL_NAME = 'sentence-transformers/LaBSE'\n",
        "LABEL_COLUMNS = ['race', 'asian', 'black', 'immigrant', 'other_race', 'religion', \n",
        "                 'jew', 'muslim', 'gender', 'women', 'lgbt', 'disability', 'not_hate']"
      ],
      "metadata": {
        "id": "tTNBHHB8_P2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(hatespeech_df, test_size=0.10)\n",
        "train_df.shape, val_df.shape"
      ],
      "metadata": {
        "id": "a0tRyAss_Q7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d31c518-679d-4ce3-8bb6-4c8e6a3f07b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20749, 16), (2306, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicCommentsDataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data: pd.DataFrame,\n",
        "      max_token_len: int = MAX_TOKEN_COUNT\n",
        "  ):\n",
        "    self.data = data\n",
        "    self.max_token_len = max_token_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  # called methods for indexing []\n",
        "  def __getitem__(self, index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "    text = data_row.text\n",
        "    encoded = data_row.encoding\n",
        "    labels = data_row[LABEL_COLUMNS]\n",
        "\n",
        "    # returns all multiple aspects of data separately as dict\n",
        "    return dict(\n",
        "        text = text,\n",
        "        encoded = encoded,\n",
        "        labels = torch.FloatTensor(labels)\n",
        "    )"
      ],
      "metadata": {
        "id": "eADRR8So_S4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicCommentDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, train_df, test_df, batch_size=10):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "  \n",
        "  # sets up datasets from raw data\n",
        "  def setup(self, stage=None):\n",
        "    self.train_dataset = ToxicCommentsDataset(self.train_df)\n",
        "    self.test_dataset = ToxicCommentsDataset(self.test_df)\n",
        "  \n",
        "  # returns dataloaders which are iterable, sequential access to elements in batches\n",
        "  \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
        "  \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=0, drop_last=True)\n",
        "  \n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=0, drop_last=True)"
      ],
      "metadata": {
        "id": "o0P4A2Z4_U3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicCommentTagger(pl.LightningModule):\n",
        "  def __init__(self, input_dim, n_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(768, 8192),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(8192, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(4096, 2048),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(2048, 1024),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(1024, n_classes),\n",
        "    )\n",
        "    self.criterion = nn.BCELoss()\n",
        "  \n",
        "  def forward(self, encoded, labels=None):\n",
        "    output = self.classifier(encoded)\n",
        "    output = torch.sigmoid(output)    \n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "        loss = self.criterion(output, labels)\n",
        "    return loss, output\n",
        "  \n",
        "  # runs each type of data through model\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    encoded = batch[\"encoded\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(encoded, labels)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "  \n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    encoded = batch[\"encoded\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(encoded, labels)\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "  \n",
        "  def test_step(self, batch, batch_idx):\n",
        "    encoded = batch[\"encoded\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(encoded, labels)\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "  \n",
        "  # evaluates results of model at end of epoch\n",
        "  def training_epoch_end(self, outputs):\n",
        "    # boilerplate to get labels and predictions out of model pipeline\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "      # detach() takes each out of pipeline, cpu() moves data to cpu\n",
        "      for out_labels in output[\"labels\"].detach().cpu():\n",
        "        labels.append(out_labels)\n",
        "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "        predictions.append(out_predictions)\n",
        "    \n",
        "    labels = torch.stack(labels).int()\n",
        "    predictions = torch.stack(predictions)\n",
        "\n",
        "    for i, name in enumerate(LABEL_COLUMNS):\n",
        "      if name not in ['race', 'religion', 'gender', 'disability', 'not_hate']:\n",
        "        continue\n",
        "      # auroc = area under reciever operating characteristic,\n",
        "      # metric used to evaluate classification models\n",
        "      class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
        "      # logs results\n",
        "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
        "  \n",
        "  # uses AdamW optimizer, schedule adjusts learning rate during training\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = AdamW(self.parameters(), lr=6e-5)\n",
        "    return dict(\n",
        "        optimizer=optimizer\n",
        "    )"
      ],
      "metadata": {
        "id": "n8LwAl3w_Wsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('trained_model_larger.pickle', 'rb') as saved_model_file:\n",
        "  saved_model = pickle.load(saved_model_file)\n",
        "trained_model = saved_model"
      ],
      "metadata": {
        "id": "4uo8GB7N_Ypo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "e8fd1668-7387-4f9e-8373-6cc4cb8998ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b463b0548beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained_model_larger.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heuristic Testing"
      ],
      "metadata": {
        "id": "imYxdmqc9YkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labse = SentenceTransformer('sentence-transformers/LaBSE')"
      ],
      "metadata": {
        "id": "qMaO0T6-9UMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = '돈이전부는 아니라지만 첫째가 돈이 먼저지 이세상 에는 돈으로 세상을사니ㅠ'\n",
        "test_comment = train_df['text'].str.contains(comment, regex=False)\n",
        "print (test_comment)\n",
        "num = 0\n",
        "for index, value in test_comment.items():\n",
        "  if (value is True):\n",
        "    print(index)\n",
        "    print(train_df.loc[index].text)\n",
        "    num+=1\n",
        "print(num)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRkAJ7dRlroP",
        "outputId": "99dbfb79-9448-4fff-d136-cceca629b1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20591                          False\n",
            "16434                          False\n",
            "3507                           False\n",
            "4406976_gab                    False\n",
            "10141                          False\n",
            "                               ...  \n",
            "1178762932198481922_twitter    False\n",
            "28460                          False\n",
            "8999391_gab                    False\n",
            "12553                          False\n",
            "20050                          False\n",
            "Name: text, Length: 20749, dtype: bool\n",
            "2099\n",
            "2099             돈이전부는 아니라지만 첫째가 돈이 먼저지 이세상 에는 돈으로 세상을사니ㅠ\n",
            "2099    There are a few things which i will definitely...\n",
            "Name: text, dtype: object\n",
            "1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_comment = train_df.loc[5293].text\n",
        "print(test_comment)\n",
        "encoding = labse.encode(test_comment)\n",
        "_, test_prediction = trained_model(torch.tensor(encoding))\n",
        "test_prediction = test_prediction.flatten().numpy()\n",
        "classes = []\n",
        "highest = 0\n",
        "highestClass = ''\n",
        "for label, prediction in zip(LABEL_COLUMNS, test_prediction):\n",
        "  print(f\"{label}: {prediction}\")\n",
        "  if prediction > highest and label is not 'not_hate':\n",
        "    highest = prediction\n",
        "    highestClass = label\n",
        "  if prediction > 0.5:\n",
        "    classes.append(label)\n",
        "  else:\n",
        "    accepted = ['asian', 'other_race', 'jew', 'disability', 'muslim', 'lgbt']\n",
        "    if (label in accepted and prediction > 0.3):\n",
        "      classes.append(label)\n",
        "\n",
        "  if label == 'not_hate' and prediction > 0.45:\n",
        "    classes.clear()\n",
        "  elif label == 'not_hate' and prediction <= .45 and highestClass not in classes:\n",
        "    classes.append(highestClass)\n",
        "\n",
        "print(\"classes: \")\n",
        "print(classes)\n",
        "\n",
        "if test_prediction[-1] > 0.45:\n",
        "  print(\"not hate\")\n",
        "else:\n",
        "  print(\"hateful\")"
      ],
      "metadata": {
        "id": "kSVOLqOu9apW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886a1b46-43db-49ff-ac01-7a3d6e29cfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UK diversity is a one of its main strengths. Immigrants are resilient, hardworking and outgoing. I particularly love when they live in immigrant-neighbourhoods and do not mix up with the rest.\n",
            "race: 0.9113994240760803\n",
            "asian: 0.02068265713751316\n",
            "black: 0.007221808657050133\n",
            "immigrant: 0.9150980710983276\n",
            "other_race: 0.051347944885492325\n",
            "religion: 0.004964934661984444\n",
            "jew: 0.00026572486967779696\n",
            "muslim: 0.00519524235278368\n",
            "gender: 5.032298213336617e-05\n",
            "women: 1.2493173926486634e-05\n",
            "lgbt: 5.8734643971547484e-05\n",
            "disability: 0.0033514583483338356\n",
            "not_hate: 0.119871124625206\n",
            "classes: \n",
            "['race', 'immigrant']\n",
            "hateful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.summarize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFvrUwceu_31",
        "outputId": "33273a7d-84ac-4aae-9e97-2036d7e83585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: LightningDeprecationWarning: The `LightningModule.summarize` method is deprecated in v1.5 and will be removed in v1.7. Use `pytorch_lightning.utilities.model_summary.summarize` instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:472: LightningDeprecationWarning: Argument `mode` in `LightningModule.summarize` is deprecated in v1.4 and will be removed in v1.6. Use `max_depth=1` to replicate `mode=top` behavior.\n",
            "  \"Argument `mode` in `LightningModule.summarize` is deprecated in v1.4\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  | Name       | Type       | Params\n",
              "------------------------------------------\n",
              "0 | classifier | Sequential | 50.4 M\n",
              "1 | criterion  | BCELoss    | 0     \n",
              "------------------------------------------\n",
              "0         Trainable params\n",
              "50.4 M    Non-trainable params\n",
              "50.4 M    Total params\n",
              "201.441   Total estimated model params size (MB)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rigorous Testing"
      ],
      "metadata": {
        "id": "A_nx4r0FTvsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can calculate the accuracy of the module using the validation set."
      ],
      "metadata": {
        "id": "Q5nzm4j9WX4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "trained_model = trained_model.to(device)\n",
        "\n",
        "val_dataset = ToxicCommentsDataset(\n",
        "  val_df,\n",
        "  max_token_len=MAX_TOKEN_COUNT\n",
        ")\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for item in tqdm(val_dataset):\n",
        "  _, prediction = trained_model(torch.tensor(item[\"encoded\"]).unsqueeze(dim=0).to(device) )\n",
        "  predictions.append(prediction.flatten())\n",
        "  labels.append(item[\"labels\"].int())\n",
        "\n",
        "predictions = torch.stack(predictions).detach().cpu()\n",
        "labels = torch.stack(labels).detach().cpu()\n",
        "\n",
        "accuracy(predictions, labels, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "db593edfcb174c8aa6b920a45e098b69",
            "32d16ab5561f458588ee241e8d5cfbe4",
            "b46d5f2969364a27a2e47e56e6e43ddf",
            "addba4278f404e60bbe6fbd193387264",
            "ee5b76fe36f34b2498dc0feed1cd1e79",
            "738bc9c8486846b48c9be5dda08b00ec",
            "3c3a81ffdaa7432395e4b5307fc8155a",
            "5f082a846a28449087194e1e06ad77a0",
            "bdb36c9cef1d4c8c8e4bcecde2b606d9",
            "97339142b419463ba69cce57eca2771a",
            "4448356d2a094d19bcecdfa6a9c5f4c1"
          ]
        },
        "id": "OD-p7FXRTzLs",
        "outputId": "d181deed-2e9e-494a-94a9-3dd1129a29b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db593edfcb174c8aa6b920a45e098b69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2306 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9197)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can calculate the AUROC for each label."
      ],
      "metadata": {
        "id": "OZhza8JZZBwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AUROC per tag\")\n",
        "for i, name in enumerate(LABEL_COLUMNS):\n",
        "  tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
        "  print(f\"{name}: {tag_auroc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm7vyxJyW4z_",
        "outputId": "eb9f69ed-60eb-470b-c4ed-7164381894b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC per tag\n",
            "race: 0.9039750695228577\n",
            "asian: 0.9636693596839905\n",
            "black: 0.9272775650024414\n",
            "immigrant: 0.9697491526603699\n",
            "other_race: 0.8894108533859253\n",
            "religion: 0.9588590860366821\n",
            "jew: 0.9614421129226685\n",
            "muslim: 0.9733967781066895\n",
            "gender: 0.9205159544944763\n",
            "women: 0.9363411664962769\n",
            "lgbt: 0.9306183457374573\n",
            "disability: 0.9156815409660339\n",
            "not_hate: 0.8065183758735657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can create a classification report ."
      ],
      "metadata": {
        "id": "DRrzKiAtZN4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predictions.numpy()\n",
        "y_true = labels.numpy()\n",
        "upper, lower = 1, 0\n",
        "y_pred = np.where(y_pred > 0.5, upper, lower)\n",
        "print(classification_report(\n",
        "  y_true,\n",
        "  y_pred,\n",
        "  target_names=LABEL_COLUMNS,\n",
        "  zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaehMUezZFul",
        "outputId": "245b72f3-905e-430e-83e7-fd6bf88a197c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        race       0.67      0.79      0.72       593\n",
            "       asian       0.64      0.65      0.64       104\n",
            "       black       0.67      0.69      0.68       242\n",
            "   immigrant       0.66      0.69      0.67        94\n",
            "  other_race       0.62      0.47      0.54       155\n",
            "    religion       0.85      0.76      0.80       484\n",
            "         jew       0.83      0.65      0.73       220\n",
            "      muslim       0.84      0.77      0.80       252\n",
            "      gender       0.72      0.77      0.74       621\n",
            "       women       0.68      0.65      0.66       269\n",
            "        lgbt       0.71      0.70      0.71       361\n",
            "  disability       0.61      0.23      0.33        61\n",
            "    not_hate       0.64      0.49      0.56       598\n",
            "\n",
            "   micro avg       0.71      0.68      0.70      4054\n",
            "   macro avg       0.70      0.64      0.66      4054\n",
            "weighted avg       0.71      0.68      0.69      4054\n",
            " samples avg       0.67      0.66      0.66      4054\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SRbJ8XC0ZS10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}